# üöÄ ML-Docker-Orchestrator with Full MLops Pipeline

A containerized machine learning deployment pipeline using **PyTorch**, **Docker Compose**, **Kubernetes**, **Terraform**, **Ansible**, **Apache Kafka**, and **Snowflake**.
https://codecov.io/gh/Trojan3877/ML-Docker-Orchestrator/branch/main/graph/badge.svg
![Coverage](https://codecov.io/gh/Trojan3877/<REPO>/branch/main/graph/badge.svg)


![Docker](https://img.shields.io/badge/Containerized-Docker-informational)
![Kubernetes](https://img.shields.io/badge/Orchestrator-Kubernetes-blue)
![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-success)
![ML-Framework](https://img.shields.io/badge/Framework-PyTorch-red)
![IaC](https://img.shields.io/badge/Infrastructure-Terraform-purple)
![Provisioning](https://img.shields.io/badge/Provisioning-Ansible-yellow)
![Streaming](https://img.shields.io/badge/Streaming-Apache_Kafka-orange)
![DataWarehouse](https://img.shields.io/badge/Data-Snowflake-lightblue)
![License](https://img.shields.io/badge/License-MIT-green)
[![Deploy to Render](https://img.shields.io/badge/Deploy-Render-blueviolet.svg)](https://render.com)
---
üåê Live API: https://<ML-DOCKER-ORCHESTRATOR.onrender.com
## üß† Architecture Flowchart

![image](https://github.com/user-attachments/assets/d9044d80-a9d7-42f7-8957-19bd2e9e9e77)



---
## üöÄ Quickstart ‚Äî Run the Full MLOps Pipeline Locally

Get the complete ML Docker orchestration and MLOps pipeline running on your machine in just a few minutes.

This Quickstart will help you:
- Clone the repo
- Configure environment variables
- Build and run all services with Docker
- Verify the ML API is live
- Run basic tests

---

### üìå Prerequisites

Make sure you have the following installed:

- **Git**
- **Docker** (v20+)
- **Docker Compose** (v2+)
- **Python 3.8+** (for local scripts/tests)
- **pip**

Optional (for Kubernetes mode):
- **kubectl**
- **minikube** or **kind**

Check versions:

```bash
docker --version
docker compose version
python --version
Clone the Repository

Bash
git clone https://github.com/Trojan3877/ML-Docker-Orchestrator-with-full-MLops-pipeline.git
cd ML-Docker-Orchestrator-with-full-MLops-pipeline
‚öôÔ∏è 2Ô∏è‚É£ Configure Environment
Create your environment file:
Bash
cp .env.example .env
Edit .env and adjust as needed:
Env
API_PORT=8000
MODEL_NAME=baseline_model
ENV=dev
Build & Launch with Docker Compose
Spin up the full local stack:
Bash
docker compose up --build
Verify the ML API
Once running, open another terminal and check:
Bash
curl http://localhost:8000/health
Expected output:
Json
{"status": "ok"}
You can also open in browser:

http://localhost:8000/docs
to see the FastAPI Swagger UI.
Run Tests
Run unit/integration tests locally:
Bash
pytest
Or inside the API container:
Bash
docker compose exec api pytest
 Check Running Services

Bash
docker compose ps
View logs:
Bash
docker compose logs -f
Stop the Stack
Bash
docker compose down
To remove volumes too:
Bash
docker compose down -v
## üìÇ Project Structure

```plaintext
ML-Docker-Orchestrator/
‚îú‚îÄ‚îÄ model/train.py
‚îú‚îÄ‚îÄ app/main.py
‚îú‚îÄ‚îÄ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ k8s/deployment.yaml
‚îú‚îÄ‚îÄ terraform/main.tf
‚îú‚îÄ‚îÄ ansible/provision.yml
‚îú‚îÄ‚îÄ snowflake/connect_snowflake.py
‚îú‚îÄ‚îÄ apache/stream_data.py
‚îú‚îÄ‚îÄ tests/test_api.py
‚îú‚îÄ‚îÄ notebooks/eda_snowflake_data.ipynb
‚îú‚îÄ‚îÄ .github/workflows/ci.yml
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ visual_flowchart.png
